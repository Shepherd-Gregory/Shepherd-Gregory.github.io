% Encoding: UTF-8

@Article{yang2021crmi,
  author   = {Xu, Yang and Zheng<sup>#</sup>, Ronghao and Liu, Meiqin and Zhang, Senlin},
  journal  = {IEEE Robotics and Automation Letters (presented at IROS 2021)},
  title    = {{CRMI}: Confidence-rich Mutual Information for Information-theoretic Mapping},
  year     = {2021},
  number   = {4},
  pages    = {6434-6441},
  volume   = {6},
  abbr     = {ral_2021},
  code     = {https://github.com/Shepherd-Gregory/CRMI},
  doi      = {10.1109/LRA.2021.3093023},
  video    = {https://youtu.be/pUcGST2W_m8},
  webpage  = {https://ieeexplore.ieee.org/abstract/document/9466474/},
  abstract = {This letter focuses on information-theoretic active mapping and exploration with beam-based range sensing robots. Traditional works based on hand-engineered inverse sensor model (ISM) mapping or kernel inference methods lead to imbalanced accuracy and efficiency. This motivates us to propose a new approach to compute mutual information more accurately, based on the continuous belief distribution over the occupancy map and called confidence-rich mutual information (CRMI). Specifically, we explicitly model the measurement dependencies between grid cells within the same measurement cone at each time step and derive the CRMI for each cell on all beams by introducing a more general beam-based sensor cause model (SCM), rather than the customized ISM. The time efficiency for CRMI mapping allows for online implementation as well. Extensive simulations and experiments show the desired exploratory behavior to unexplored and obscured regions for CRMI-based robot controllers in the unstructured and cluttered scene, even in large scale environment.},
}

@Article{xu2024uncertain,
  author  = {Xu, Yang and Zheng<sup>#</sup>, Ronghao and Zhang, Senlin and Liu, Meiqin and Yu, Junzhi},
  journal = {IEEE Transactions on Automation Science and Engineering},
  title   = {Uncertainty-Aware Autonomous Robot Exploration Using Confidence-Rich Localization and Mapping},
  year    = {2024},
  pages   = {1-15},
  abbr    = {tase-ucrmi},
  doi     = {10.1109/TASE.2024.3360442},
  webpage = {https://ieeexplore.ieee.org/abstract/document/10422987/},
  abstract = {Information-based autonomous robot exploration methods, aiming to maximize the exploration rewards, e.g., mutual information (MI), get more prevalent in field robotics applications. However, most MI-based exploration methods assume known poses or use inaccurate pose uncertainty approximation, which may lead to deviation or even failure when exploring prior unknown environments. In this paper, we explicitly consider full-state (pose & map) uncertainty for balancing exploration and localizability, i.e., avoiding the robot guiding itself to complex scenes with high exploration rewards but hard to localize. We first propose a Rao-Blackwellized particle filter-based localization and mapping framework (RBPF-CLAM) for a dense environmental map with continuous occupancy distribution. Then we develop a new closed-form particle weighting method to improve the localization accuracy and robustness. We further use these weighted particles to approximate the unknown pose uncertainty and combine it with our previous confidence-rich mutual information (CRMI) metric to evaluate the expected information utility of the robot’s new control actions. This new information metric is called uncertain CRMI (UCRMI). Dataset experiments show our RBPF-CLAM improves about 44.7% average root mean square error than the state-of-the-art RBPF localization method, and real-world experimental results show that our UCRMI reduces the pose uncertainty about 32.85% more than CRMI and 25.36% time cost than UGPVR in the exploration of unknown and unstructured scenes given sparse measurements, which shows better performance than other state-of-the-art information metrics.},
}

@Article{xu2024online,
  author  = {Xu, Yang and Zheng<sup>#</sup>, Ronghao and Zhang, Senlin and Liu, Meiqin and Yu, Junzhi},
  journal = {IEEE Transactions on Circuits and Systems II: Express Briefs},
  title   = {Online Informative Path Planning of Autonomous Vehicles Using Kernel-Based Bayesian Optimization},
  year    = {2024},
  pages   = {1-1},
  abbr    = {tcasii-2024},
  doi     = {10.1109/TCSII.2024.3368081},
  webpage = {https://ieeexplore.ieee.org/abstract/document/10443243/},
  abstract = {To improve environmental information gathering of intelligent vehicles in unknown scenes, this brief presents a hierarchical online informative path planning (IPP) framework containing global action optimization and local path planning. Particularly, we propose a lightweight kernel-based Bayesian optimization for IPP (KBO-IPP) to facilitate highly efficient information utility evaluation and decision-making of control actions. Specifically, KBO-IPP can infer the exact environmental mutual information (MI) and associated uncertainties with an approximate logarithmic complexity, eliminating the need for explicit model training. We develop a new information-theoretic objective function consisting of travel cost and predicted MI values with uncertainties to achieve the balance between high MI values (exploitation) and high prediction variances (exploration). To enhance the optimality of IPP, the past unselected informative actions are also incorporated into the global Bayesian optimization. Online real-world experiments validate that our proposed method shows higher efficiency with comparable performance to modern methods in unknown, complex environments.},
}

@InProceedings{xu2022confidence,
  author    = {Xu, Yang and Zheng<sup>#</sup>, Ronghao and Zhang, Senlin and Liu, Meiqin},
  booktitle = {2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title     = {Confidence-rich Localization and Mapping based on Particle Filter for Robotic Exploration},
  year      = {2022},
  pages     = {4471-4477},
  abbr      = {iros_clam},
  arxiv     = {2309.05200},
  doi       = {10.1109/IROS47612.2022.9981251},
  webpage   = {https://ieeexplore.ieee.org/abstract/document/9981251/},
  abstract  = {This paper mainly studies the localization and mapping of range sensing robots in the confidence-rich map (CRM) and then extends it to provide a full state estimate for information-theoretic exploration. Most previous works about active simultaneous localization and mapping and exploration always assumed the known robot poses or utilized inaccurate information metrics to approximate pose uncertainty, resulting in imbalanced exploration performance and efficiency in the unknown environment. This inspires us to extend the confidence-rich mutual information (CRMI) with measurable pose uncertainty. Specifically, we propose a Rao- Blackwellized particle filter-based localization and mapping scheme (RBPF -CLAM) for CRM, then we develop a new closed-form weighting method to improve the localization accuracy without scan matching. We further derive the uncertain CRMI (UCRMI) with the weighted particles by a more accurate approximation. Simulations and experimental evaluations show the localization accuracy and exploration performance of the proposed methods.},
  video     = {https://youtu.be/t7awYSnC2dw},
}

@InProceedings{xu2020keyframe,
  author    = {Xu, Yang and Zheng<sup>#</sup>, Ronghao and Liu, Meiqin and Zhang, Senlin},
  booktitle = {Global Oceans 2020: Singapore – U.S. Gulf Coast},
  title     = {Keyframe-Based Imaging Sonar Localization and Navigation using Elastic Windowed Optimization},
  year      = {2020},
  pages     = {1-7},
  abbr      = {oceans20},
  webpage   = {https://ieeexplore.ieee.org/abstract/document/9389045/},
  abstract  = {This paper reports a sonar keyframe-based elastic windowed optimization scheme for underwater localization and navigation using a 2D forward-looking imaging sonar. Due to the sparse acoustic features and the missing elevation angle in sonar images, degeneracy cases (namely under-constrained), such as relative pose ambiguity, exist in underwater sonar simultaneous localization and mapping (SLAM). To extract and fully utilize informative constraints from past sonar frames, we first identify the degeneracy case and choose sonar keyframes (KFs) using the effective information volume criteria. Secondly, we present an elastic windowed optimization framework in which the window size is adjusted according to certain rules. This scheme is also more robust to outliers from the frontend. Finally, the feasibility and effectiveness of the proposed method are verified through the comparative simulation.},
  doi       = {10.1109/IEEECONF38699.2020.9389045},
}

@Article{bai2022hierarchical,
  author    = {Bai, Ruofei and Zheng<sup>#</sup>, Ronghao and Xu, Yang and Liu, Meiqin and Zhang, Senlin},
  journal   = {Robotics and Autonomous Systems},
  title     = {Hierarchical Multi-robot Strategies Synthesis and Optimization under Individual and Collaborative Temporal Logic Specifications},
  year      = {2022},
  pages     = {104085},
  volume    = {153},
  abbr      = {ras_bai},
  arxiv     = {2110.11162},
  doi       = {10.1016/j.robot.2022.104085},
  webpage   = {https://www.sciencedirect.com/science/article/pii/S0921889022000422},
  abstract  = {This paper presents a hierarchical framework for multi-robot temporal logic task planning. We assume that each robot has its individual task specification and the robots have to jointly satisfy a global collaborative task specification, both described in finite linear temporal logic. To reduce the overall computational complexity, a central server firstly extracts and decomposes a collaborative task sequence from the automaton corresponding to the collaborative task specification, and allocates the subtasks in the sequence to robots. The robots then synthesize their initial execution strategies based on locally constructed product automatons, which integrate task requirements of the assigned collaborative tasks and their individual task specifications. Further, to reduce robots’ wait time in collaborations, we propose a distributed execution strategy adjusting mechanism to iteratively improve the time efficiency of robots. Finally, we prove the completeness of the proposed framework under assumptions, and analyze its time complexity and optimality. Extensive simulation results verify the scalability and optimization efficiency of the proposed method.},
  publisher = {Elsevier},
}

@Article{xu2023care,
  author    = {Xu, Yang and Zheng<sup>#</sup>, Ronghao and Zhang, Senlin and Liu, Meiqin and Huang, Shoudong},
  journal   = {IEEE Robotics and Automation Letters (presented at ICRA 2024)},
  title     = {CARE: Confidence-rich Autonomous Robot Exploration using Bayesian Kernel Inference and Optimization},
  year      = {2023},
  abbr      = {care_2023},
  arxiv     = {2309.05200},
  code      = {https://github.com/Shepherd-Gregory/BKIO-Exploration},
  doi       = {10.1109/LRA.2023.3313054},
  webpage   = {https://ieeexplore.ieee.org/abstract/document/10243037/},
  supp      = {RAL23_arxiv_full.pdf},
  abstract  = {In this letter, we consider improving the efficiency of information-based autonomous robot exploration in unknown and complex environments. We first utilize Gaussian process (GP) regression to learn a surrogate model to infer the confidence-rich mutual information (CRMI) of querying control actions, then adopt an objective function consisting of predicted CRMI values and prediction uncertainties to conduct Bayesian optimization (BO), i.e., GP-based BO (GPBO). The trade-off between the best action with the highest CRMI value (exploitation) and the action with high prediction variance (exploration) can be realized. To further improve the efficiency of GPBO, we propose a novel lightweight information gain inference method based on Bayesian kernel inference and optimization (BKIO), achieving an approximate logarithmic complexity without the need for training. BKIO can also infer the CRMI and generate the best action using BO with bounded cumulative regret, which ensures its comparable accuracy to GPBO with much higher efficiency. Extensive numerical and real-world experiments show the desired efficiency of our proposed methods without losing exploration performance in different unstructured, cluttered environments.},
  publisher = {IEEE},
}

@Article{yang2022robust,
  author    = {Xu, Yang and Zheng<sup>#</sup>, Ronghao and Zhang, Senlin and Liu, Meiqin},
  journal   = {IEEE Transactions on Instrumentation and Measurement},
  title     = {Robust Inertial-aided Underwater Localization based on Imaging Sonar Keyframes},
  year      = {2022},
  number    = {7501812},
  pages     = {1--12},
  volume    = {71},
  abbr      = {tim-2022},
  arxiv     = {2106.16032},
  doi       = {10.1109/TIM.2022.3156980},
  webpage   = {https://ieeexplore.ieee.org/abstract/document/9729232/},
  abstract  = {This article focuses on feature-based underwater localization and navigation for autonomous underwater vehicles (AUVs) using 2-D imaging sonar measurements. The sparsity of underwater acoustic features and the loss of elevation angle in sonar images may introduce wrong feature matches or insufficient features for optimization-based underwater localization (i.e., underconstrained/degeneracy cases). This motivates us to propose a novel inertial-aided sliding window optimization framework to improve the estimation accuracy and the robustness to front-end outliers. Concretely, we first discriminate underconstrained/well-constrained sonar frames and define sonar keyframes (SKFs) based on the Jacobian matrix derived from odometry and sonar measurements. To utilize the past well-constrained SKFs mostly, we design a size-adjustable windowed back-end optimization scheme based on singular values. We also prove that the landmark triangulation failure (navigation problem) caused by sonar motion can be solved in 2-D scenes. Comparative simulation and evaluation on a public dataset show that the proposed method outperforms the existing ones in pose estimation and robustness even without loop closure and also ensures the real-time performance for online applications.},
  publisher = {IEEE},
}

@InProceedings{zhu2025task,
  author    = {Zhu, Shaohao and Zhao, Yixian and Xu, Yang and Chen, Anjun and Chen, Jiming and Xu<sup>#</sup>, Jinming},
  booktitle = {2025 IEEE International Conference on Robotics and Automation (ICRA)},
  title     = {{TaskExp:} Enhancing Generalization of Multi-Robot Exploration with Multi-Task Pre-Training},
  year      = {2025},
  pages     = {1-7},
  abbr      = {icra_taskexp},  
  abstract  = {We aim to develop a general multi-agent reinforcement learning (MARL) policy that enables a group of robots to efficiently explore large-scale, unknown environments with random pose initialization. Existing MARL-based multirobot exploration methods face challenges in reliably mapping observations to actions in large-scale scenarios and lack of zero-shot generalization to unknown environments. To this end, we propose a generic multi-task pre-training algorithm (termed TaskExp) to enhance the generalization of learningbased policies. In particular, we design a decision-related task to guide the policy to focus on valuable subspaces of the action space, improving the reliability of policy mapping. Moreover, two perception-related tasks–Location Estimation and Map Prediction–are designed to enhance the zero-shot capability of the policy by guiding it to extract general invariant features from unknown environments. With TaskExp pre-training, our policy significantly outperforms state-of-the-art planningbased methods in large-scale scenarios and demonstrates strong zero-shot performance in unseen environments. Furthermore, TaskExp can also be easily integrated to improve the existing learning-based multi-robot exploration methods.},
}

@InProceedings{qian2025afrlio,
  author    = {Qian*, Chenglong and Xu*, Yang and Shi, Xiufang and Chen, Jiming and Li<sup>#</sup>, Liang},
  booktitle = {2025 IEEE International Conference on Robotics and Automation (ICRA)},
  title     = {AF-RLIO: Adaptive Fusion of Radar-LiDAR-Inertial Information for Robust Odometry in Challenging Environments},
  year      = {2025},
  pages     = {1-7},
  abbr      = {icra_afrlio},
  abstract  = {In robotic navigation, maintaining precise pose estimation and navigation in complex and dynamic environments is crucial. However, environmental challenges such as smoke, tunnels, and adverse weather can significantly degrade the performance of single-sensor systems like LiDAR or GPS, compromising the overall stability and safety of autonomous robots. To address these challenges, we propose AF-RLIO: an adaptive fusion approach that integrates 4D millimeterwave radar, LiDAR, inertial measurement unit (IMU), and GPS to leverage the complementary strengths of these sensors for robust odometry estimation in complex environments. Our method consists of three key modules. Firstly, the pre-processing module utilizes radar data to assist LiDAR in removing dynamic points and determining when environmental conditions are degraded for LiDAR. Secondly, the front-end odometry selects appropriate point cloud data for scan-to-submap matching and tightly couples it with the IMU using the Iterative Error State Kalman Filter. Lastly, the back-end optimization module balances weights between front-end odometry and GPS data, constructing a pose graph for optimization. The proposed approach has been evaluated on datasets and tested in realworld robotic environments, demonstrating its effectiveness and advantages over existing methods in challenging conditions such as smoke and tunnels.},
}

@Article{li2025deform,
  author   = {Jin Li*, Yang Xu*, Xiufang Shi, Liang Li<sup>#</sup>},
  journal  = {IEEE Robotics and Automation Letters (RA-L)},
  title    = {DEFORM: Adaptive Formation Reconfiguration of Multi-robot Systems inConfined Environments},
  year     = {2025},
  abbr	   = {ral_deform},
  abstract = {Achieving desired formation patterns without collisions is rather challenging for multi-robot systems in unknown obstacle-rich and confined environments, especially in narrow corridor scenes containing large-volume obstacles. To address this, we propose an adaptive formation reconfiguration method that can dynamically switch to the optimal formation pattern based on the current obstacle distribution. Specifically, we develop a novel obstacle-free maximum passable width detection method to formulate recursive optimization problems, which can determine the currently best formation shape and refine local goals away from obstacles. Then we design a task assignment module for the temporary leader robot and a consensus-based distributed formation controller for each robot using model predictive control to ensure rapid convergence to the suggested formation shape. In addition, we utilize the potential field approach for each robot to improve collision avoidance. Extensive Gazebo simulations and real-world experiments in confined and obstacle-rich scenes verify the superior performance of our methods compared to cutting-edge methods.},
}

@Comment{jabref-meta: databaseType:bibtex;}
