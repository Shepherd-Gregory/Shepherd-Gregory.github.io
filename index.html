<!DOCTYPE html>
<html>

  <head>
    
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>

  Yang Xu


</title>
<meta name="description" content="Yang Xu's personal webpage.
">

<!-- Open Graph -->

<meta property="og:site_name" content="Yang Xu's personal webpage.
" />
<meta property="og:type" content="object" />
<meta property="og:title" content="" />
<meta property="og:url" content="https://shepherd-gregory.github.io/" />
<meta property="og:description" content="about" />
<meta property="og:image" content="" />


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<!-- <link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" /> -->

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸŒž</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->

<script src="/assets/js/theme.js"></script>
<script src="/assets/js/dark_mode.js"></script>



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id="></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag('js', new Date());

  gtag('config', '');
</script>




    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav sticky-bottom-footer">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
        <!-- Social Icons -->
        <div class="navbar-brand social">
          <a href="mailto:%78%75%79%61%6E%67%39%34@%7A%6A%75.%65%64%75.%63%6E"><i class="fas fa-envelope"></i></a>

<a href="https://scholar.google.com/citations?user=0jlkaLsAAAAJ" title="Google Scholar" target="_blank" rel="noopener noreferrer"><i class="ai ai-google-scholar"></i></a>


<a href="https://github.com/Shepherd-Gregory" title="GitHub" target="_blank" rel="noopener noreferrer"><i class="fab fa-github"></i></a>
<a href="https://www.linkedin.com/in/yang-xu-142337109" title="LinkedIn" target="_blank" rel="noopener noreferrer"><i class="fab fa-linkedin"></i></a>












<!--  -->

        </div>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item active">
            <a class="nav-link" href="/">
              Home
              
                <span class="sr-only">(current)</span>
              
            </a>
          </li>
          
          <!-- Blog -->
          <li class="nav-item ">
            <a class="nav-link" href="https://shepherd-gregory.github.io/#publications">Publications</a>
          </li>
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/projects/">
                Posts
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/teaching/">
                Teaching
                
              </a>
          </li>
          
          
          
          
          
          
          
          
            <div class="toggle-container">
              <a id="light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">
     Yang Xu
    </h1>
     <p class="desc">Postdoc Research Fellow, <a href="https://person.zju.edu.cn/xuyang94" target="_blank" rel="noopener noreferrer"> ZJU Homepage(CN)</a></p>
  </header>

  <article>
    
    <div class="profile float-right">
      
        <img class="img-fluid z-depth-1 rounded" src="/assets/img/snowyoung.jpg">
      
      
    </div>
    

    <div class="clearfix">
      <h2><font color="#0000dd">Brief bio</font></h2>

<p>I am currently a Postdoc supervised by Prof. <a href="https://person.zju.edu.cn/en/jmchen" target="_blank" rel="noopener noreferrer">Jiming Chen</a> at <strong>Zhejiang University</strong>, China. Prior to this, I received my D. Eng. degree in robotics from <strong>Zhejiang University</strong> at 2023, supervised by Prof. Meiqin Liu and Prof. Ronghao Zheng.  From 2022 to 2023, I was  also a visiting scholar with the <strong>Robotics Institute, University of Technology Sydney (UTS)</strong> supervised by Prof. <a href="https://www.uts.edu.au/staff/shoudong.huang" target="_blank" rel="noopener noreferrer">Shoudong Huang</a>.</p>

<div class="row  align-items-center">
    <div class="col-sm mt-3 mt-md-0">
        <img class="img-fluid " src="/assets/img/affiliations/compound.png" alt="" title="example image">
    </div>
</div>

<hr>

<h2>Research interests</h2>

<p>My research interests include active SLAM, autonomous exploration, informative path planning, and robot learning.  My current research projects mainly focus on <strong>learning-based robot exploration in hazardous and complex environments</strong>. Welcome to reach out via email: <a href="mailto:garryhsu0901@gmail.com">garryhsu0901@gmail.com</a>(Permanent)/<a href="mailto:xuyang94@zju.edu.cn">xuyang94@zju.edu.cn</a> (Academic).</p>

<hr>

<div class="news">
  
    <div class="news">
  <h2>News</h2>
  
    <div class="table-responsive" style="height: 350px; overflow-y:scroll">
      <table class="table table-sm table-borderless" style="width: 100%">
      
      
        <tr>
          <th scope="row" style="width:15%">Oct 3, 2025</th>
          <td>
            
              Invited to chair the session of <strong>Computer Vision for Transportation 2</strong> (WeDT24), welcome to reach out at <strong>IROS 2025</strong> Hangzhou!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row" style="width:15%">Oct 2, 2025</th>
          <td>
            
              One paper accepted by <strong>T-Mech</strong> as regular paper!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row" style="width:15%">Sep 18, 2025</th>
          <td>
            
              Appointed as Young Editorial Board Member of <strong>IET Cyber-Systems and Robotics (IET-CSR)</strong>!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row" style="width:15%">Sep 4, 2025</th>
          <td>
            
              One paper accepted by <strong>IEEE IOT-J 2025</strong>, congrats to <strong>Jing Zeng</strong> !

            
          </td>
        </tr>
      
        <tr>
          <th scope="row" style="width:15%">Aug 1, 2025</th>
          <td>
            
              Appointed as a member of the Young Editorial Board of <strong>BiRob</strong> (IF 5.4, Q1)!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row" style="width:15%">Jun 30, 2025</th>
          <td>
            
              Appointed as the <strong>Associate Editor</strong> of <strong>SII 2026</strong>~

            
          </td>
        </tr>
      
        <tr>
          <th scope="row" style="width:15%">Jun 16, 2025</th>
          <td>
            
              2 paper accepted by <strong>IROS 2025</strong>, congrats to <strong>Wenhao</strong> and <strong>Bo Pang</strong> !

            
          </td>
        </tr>
      
        <tr>
          <th scope="row" style="width:15%">May 12, 2025</th>
          <td>
            
              One paper accepted by <strong>MST 2025</strong>, congrats to <strong>Shaochen</strong> !

            
          </td>
        </tr>
      
        <tr>
          <th scope="row" style="width:15%">Mar 25, 2025</th>
          <td>
            
              One paper accepted by <strong>RAL 2025</strong>, congrats to <strong>Jing Zeng</strong> !

            
          </td>
        </tr>
      
        <tr>
          <th scope="row" style="width:15%">Mar 11, 2025</th>
          <td>
            
              Appointed as the <strong>Associate Editor</strong> (regular paper) of <strong>IEEE RO-MAN</strong> 2025~

            
          </td>
        </tr>
      
        <tr>
          <th scope="row" style="width:15%">Mar 4, 2025</th>
          <td>
            
              One paper accepted by <strong>RAL 2025</strong>, congrats to <strong>Jin Li</strong> !

            
          </td>
        </tr>
      
        <tr>
          <th scope="row" style="width:15%">Jan 28, 2025</th>
          <td>
            
              Two papers accepted by <strong>ICRA 2025</strong>, congrats to <strong>Shaohao</strong> and <strong>Chenglong</strong> !

            
          </td>
        </tr>
      
        <tr>
          <th scope="row" style="width:15%">Sep 10, 2024</th>
          <td>
            
              Appointed as the <strong>Associate Editor</strong> of <strong>ICRA 2025</strong>~

            
          </td>
        </tr>
      
        <tr>
          <th scope="row" style="width:15%">Jun 22, 2024</th>
          <td>
            
              We organize an invited session in <a href="https://icus.c2.org.cn/Invited-Session/" target="_blank" rel="noopener noreferrer"><strong>IEEE ICUS</strong> 2024</a>, welcome new submissions~

            
          </td>
        </tr>
      
        <tr>
          <th scope="row" style="width:15%">Jun 15, 2024</th>
          <td>
            
              Appointed as the <strong>Associate Editor</strong> of <strong>IEEE RO-MAN</strong> 2024~

            
          </td>
        </tr>
      
      </table>
    </div>
  
</div>

  


</div>

<hr>

<h2>Academic services</h2>

<p><strong>Journal Editors</strong>: <strong>Biomimetic Intelligence and Robotics (BiRob)</strong>, Young Editorial Board; <strong>IET Cyber-Systems and Robotics (IET-CSR)</strong>, Young Editorial Board.</p>

<p><strong>Conference Editors</strong>: <strong>ICRA, Associate Editor</strong> (2025, 2026);  <strong>RO-MAN</strong>, Associate Editor (2024, 2025); <strong>SII 2026</strong>, Associate Editor.</p>

<p><b>Conference Services</b>: ICRA 2024, Session Co-Chair (SLAM); ICUS 2024/2025, PC Member/Invited Session Chair; IROS 2025. Session Chair (Computer Vision for Transportation).</p>

<p><b>Membership</b>: IEEE, IEEE Robotics and Automation Society (RAS), CCF/CAA/CAAI.</p>

<p><b>Journal Reviewer</b>: IEEE T-NNLS/RA-L/T-ASE/T-II/T-CDS/T-ITS/T-IV/T-IM/Robotics and Autonomous Systems (RAS), IEEE/CAA Journal of Automatica Sinica (JAS), IEEE Sensor Journal, Information Fusion, Measurement Science and Technology, et al.</p>

<p><b>Conference Reviewer</b>: ICRA, IROS, AIM, ICONIP, et al.</p>

<hr>

<h2>Awards</h2>

<ul>
  <li>National Postdoctoral Program for Innovative Talents (10 in automation nationwide), 2024</li>
  <li>Chinese National Scholarship for Ph.D. Students (2%), Oct. 2022</li>
  <li>Chinese Scholarship Council for Joint Ph.D. Students, Jul. 2022</li>
  <li>Academic Rising Stars of Ph.D. Students, Zhejiang University, Aug. 2022</li>
  <li>Outstanding Graduate Student of Zhejiang University, Oct. 2022</li>
</ul>

<hr>

<h2>Talks and presentations</h2>

<ul>
  <li>
    <p>2025-04-02: On-site talk at SRIAS of Tongji University. (Invited by Prof. Bin He)</p>
  </li>
  <li>
    <p><strong>ICRA 2024 (Yokohama, Japan)</strong> - CARE: Confidence-rich autonomous robot exploration using Bayesian kernel inference and optimization. <a href="https://youtu.be/xM2NbAQnvgs" target="_blank" rel="noopener noreferrer">Video</a></p>
  </li>
  <li>
    <p>2024-04-27: Online talk &amp; session chair at PRE-ICRA 2024. (Invited by CAA TC on Hybrid Intelligence)</p>
  </li>
  <li>
    <p>2023-05-18: On-site talk at <a href="https://milab.westlake.edu.cn/" target="_blank" rel="noopener noreferrer">MiLab</a> of Westlake University. (Invited by Prof. <a href="https://milab.westlake.edu.cn/index.html" target="_blank" rel="noopener noreferrer">Donglin Wang</a>)~</p>
  </li>
  <li>
    <p>2022-10-15: Online talk at PRE-IROS 2022. (Invited by CAA TC on Hybrid Intelligence)</p>
  </li>
  <li>
    <p><strong>IROS 2022 (Kyoto, Japan)</strong> - Confidence-rich localization and mapping based on particle filter for robotic exploration. <a href="https://youtu.be/t7awYSnC2dw" target="_blank" rel="noopener noreferrer">Video</a></p>
  </li>
  <li>
    <p><strong>IROS 2021 (Prague, Czech)</strong> - CRMI: Confidence-rich mutual information for information-theoretic mapping, Video here: <a href="https://youtu.be/pUcGST2W_m8" target="_blank" rel="noopener noreferrer">Youtube</a>, <a href="https://www.bilibili.com/video/BV1vQ4y1e77y?share_source=copy_web" target="_blank" rel="noopener noreferrer">Bilibili</a></p>
  </li>
</ul>

<h2>Posts and blogs</h2>

<p>See all posts here: <a href="/projects"><code class="language-plaintext highlighter-rouge">Posts</code></a></p>


    </div>

    
    
    <div class="clearfix">
    <a name="publications"><h2>Selected publications</h2></a>
    <br>
    <p style="font-size:22px;"> <i> Find out my full publication list via </i> <a href="https://scholar.google.com/citations?user=0jlkaLsAAAAJ" target="_blank" rel="noopener noreferrer">Google Scholar</a>. <br>
    <sup>*</sup> co-first author with equal contribution;  <sup>#</sup> Corresponding author.</p>  
    <!-- <sup>&#x0266F;</sup>corresponding author. -->
    
      <ol class="bibliography">
<li>
<!-- Refer to https://github.com/alshedivat/al-folio/blob/master/_layouts/bib.html
and 
https://github.com/Mayankm96/Mayankm96.github.io/blob/source/_layouts/bib.html -->
<div id="li2025deform" class="col three">
  <div style="clear: both;">
    <div style="">
        <img class="col bibone first" src="https://shepherd-gregory.github.io/assets/img/teaser/ral_deform.png">
    </div>
  </div>
  <div class="col bibtwo last">
    
      <span class="title">DEFORM: Adaptive Formation Reconfiguration of Multi-robot Systems in Confined Environments</span>
      <span class="author">
        
          
          
          
          
          
          
            
              
                
                  Jin Li*,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  <em><b>Yang</b></em> <em><b>Xu<sup>*</sup></b></em>,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Xiufang Shi,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Liang Li<sup>#</sup>
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em>IEEE Robotics and Automation Letters</em>
      
      
        
          2025
        
      
      </span>
    

    <span class="links">
    
      [<a class="abstract" style="color: $pub-theme-color">Abs</a>]
    
    
    
      [<a href="https://youtu.be/Gp7ctSpoegI" target="_blank" rel="noopener noreferrer">Video</a>]
    
    
    
      [<a href="https://ieeexplore.ieee.org/document/10933518" target="_blank" rel="noopener noreferrer">Webpage</a>]
    
    
    
    
    
    
    
    
      [<a href="https://github.com/NeSC-IV/DEFORM" target="_blank" rel="noopener noreferrer">Code</a>]
    
    </span>

    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p>Achieving desired formation patterns without collisions is rather challenging for multi-robot systems in unknown obstacle-rich and confined environments, especially in narrow corridor scenes containing large-volume obstacles. To address this, we propose an adaptive formation reconfiguration method that can dynamically switch to the optimal formation pattern based on the current obstacle distribution. Specifically, we develop a novel obstacle-free maximum passable width detection method to formulate recursive optimization problems, which can determine the currently best formation shape and refine local goals away from obstacles. Then we design a task assignment module for the temporary leader robot and a consensus-based distributed formation controller for each robot using model predictive control to ensure rapid convergence to the suggested formation shape. In addition, we utilize the potential field approach for each robot to improve collision avoidance. Extensive Gazebo simulations and real-world experiments in confined and obstacle-rich scenes verify the superior performance of our methods compared to cutting-edge methods.</p>
    </span>
    
  </div>
</div>
</li>
<li>
<!-- Refer to https://github.com/alshedivat/al-folio/blob/master/_layouts/bib.html
and 
https://github.com/Mayankm96/Mayankm96.github.io/blob/source/_layouts/bib.html -->
<div id="zhu2025task" class="col three">
  <div style="clear: both;">
    <div style="">
        <img class="col bibone first" src="https://shepherd-gregory.github.io/assets/img/teaser/icra_taskexp.png">
    </div>
  </div>
  <div class="col bibtwo last">
    
      <span class="title">TaskExp: Enhancing Generalization of Multi-Robot Exploration with Multi-Task Pre-Training</span>
      <span class="author">
        
          
          
          
          
          
          
            
              
                
                  Shaohao Zhu,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Yixian Zhao,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em><b>Yang Xu</b></em>,
              
            
          
        
          
          
          
          
            
              
            
          
          
          
            
              
                
                  Anjun Chen,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://scholar.google.com/citations?user=zK9tvo8AAAAJ&amp;hl=en" target="_blank" rel="noopener noreferrer">Jiming Chen</a>,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Jinming Xu<sup>#</sup>
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em></em>
        <br>
        <em>2025 IEEE International Conference on Robotics and Automation (ICRA)</em>
      
      
        
          2025
        
      
      </span>
    

    <span class="links">
    
      [<a class="abstract" style="color: $pub-theme-color">Abs</a>]
    
    
    
    
    
      [<a href="https://ieeexplore.ieee.org/document/11128456" target="_blank" rel="noopener noreferrer">Webpage</a>]
    
    
    
    
    
    
    
    
      [<a href="https://github.com/DuangZhu/TaskExp" target="_blank" rel="noopener noreferrer">Code</a>]
    
    </span>

    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p>We aim to develop a general multi-agent reinforcement learning (MARL) policy that enables a group of robots to efficiently explore large-scale, unknown environments with random pose initialization. Existing MARL-based multirobot exploration methods face challenges in reliably mapping observations to actions in large-scale scenarios and lack of zero-shot generalization to unknown environments. To this end, we propose a generic multi-task pre-training algorithm (termed TaskExp) to enhance the generalization of learningbased policies. In particular, we design a decision-related task to guide the policy to focus on valuable subspaces of the action space, improving the reliability of policy mapping. Moreover, two perception-related tasksâ€“Location Estimation and Map Predictionâ€“are designed to enhance the zero-shot capability of the policy by guiding it to extract general invariant features from unknown environments. With TaskExp pre-training, our policy significantly outperforms state-of-the-art planningbased methods in large-scale scenarios and demonstrates strong zero-shot performance in unseen environments. Furthermore, TaskExp can also be easily integrated to improve the existing learning-based multi-robot exploration methods.</p>
    </span>
    
  </div>
</div>
</li>
<li>
<!-- Refer to https://github.com/alshedivat/al-folio/blob/master/_layouts/bib.html
and 
https://github.com/Mayankm96/Mayankm96.github.io/blob/source/_layouts/bib.html -->
<div id="qian2025afrlio" class="col three">
  <div style="clear: both;">
    <div style="">
        <img class="col bibone first" src="https://shepherd-gregory.github.io/assets/img/teaser/icra_afrlio.png">
    </div>
  </div>
  <div class="col bibtwo last">
    
      <span class="title">AF-RLIO: Adaptive Fusion of Radar-LiDAR-Inertial Information for Robust Odometry in Challenging Environments</span>
      <span class="author">
        
          
          
          
          
          
          
            
              
                
                  Chenglong Qian*,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  <em><b>Yang</b></em> <em><b>Xu<sup>*</sup></b></em>,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Xiufang Shi,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://scholar.google.com/citations?user=zK9tvo8AAAAJ&amp;hl=en" target="_blank" rel="noopener noreferrer">Jiming Chen</a>,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Liang Li<sup>#</sup>
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em></em>
        <br>
        <em>2025 IEEE International Conference on Robotics and Automation (ICRA)</em>
      
      
        
          2025
        
      
      </span>
    

    <span class="links">
    
      [<a class="abstract" style="color: $pub-theme-color">Abs</a>]
    
    
    
    
    
      [<a href="https://ieeexplore.ieee.org/document/11128046" target="_blank" rel="noopener noreferrer">Webpage</a>]
    
    
    
    
    
    
    
    
      [<a href="https://github.com/QCL0920/AF-RLIO" target="_blank" rel="noopener noreferrer">Code</a>]
    
    </span>

    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p>In robotic navigation, maintaining precise pose estimation and navigation in complex and dynamic environments is crucial. However, environmental challenges such as smoke, tunnels, and adverse weather can significantly degrade the performance of single-sensor systems like LiDAR or GPS, compromising the overall stability and safety of autonomous robots. To address these challenges, we propose AF-RLIO: an adaptive fusion approach that integrates 4D millimeterwave radar, LiDAR, inertial measurement unit (IMU), and GPS to leverage the complementary strengths of these sensors for robust odometry estimation in complex environments. Our method consists of three key modules. Firstly, the pre-processing module utilizes radar data to assist LiDAR in removing dynamic points and determining when environmental conditions are degraded for LiDAR. Secondly, the front-end odometry selects appropriate point cloud data for scan-to-submap matching and tightly couples it with the IMU using the Iterative Error State Kalman Filter. Lastly, the back-end optimization module balances weights between front-end odometry and GPS data, constructing a pose graph for optimization. The proposed approach has been evaluated on datasets and tested in realworld robotic environments, demonstrating its effectiveness and advantages over existing methods in challenging conditions such as smoke and tunnels.</p>
    </span>
    
  </div>
</div>
</li>
<li>
<!-- Refer to https://github.com/alshedivat/al-folio/blob/master/_layouts/bib.html
and 
https://github.com/Mayankm96/Mayankm96.github.io/blob/source/_layouts/bib.html -->
<div id="zeng2025multi" class="col three">
  <div style="clear: both;">
    <div style="">
        <img class="col bibone first" src="https://shepherd-gregory.github.io/assets/img/teaser/ral_3drecon.png">
    </div>
  </div>
  <div class="col bibtwo last">
    
      <span class="title">Multi-robot autonomous 3D reconstruction using Gaussian splatting with Semantic guidance</span>
      <span class="author">
        
          
          
          
          
          
          
            
              
                
                  Jing Zeng,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Qi Ye<sup>#</sup>,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Tianle Liu,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em><b>Yang Xu</b></em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Jin Li,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Jinming Xu,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Liang Li,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  and <a href="https://scholar.google.com/citations?user=zK9tvo8AAAAJ&amp;hl=en" target="_blank" rel="noopener noreferrer">Jiming Chen</a>
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em>IEEE Robotics and Automation Letters</em>
      
      
        
          2025
        
      
      </span>
    

    <span class="links">
    
      [<a class="abstract" style="color: $pub-theme-color">Abs</a>]
    
    
    
      [<a href="https://youtu.be/qECcdHzNMZs" target="_blank" rel="noopener noreferrer">Video</a>]
    
    
    
      [<a href="https://ieeexplore.ieee.org/document/10955244" target="_blank" rel="noopener noreferrer">Webpage</a>]
    
    
    
    
    
    
    
    
    </span>

    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p>Implicit neural representations and 3D Gaussian splatting (3DGS) have shown great potential for scene reconstruction. Recent studies have expanded their applications in autonomous reconstruction through task assignment methods. However, these methods are mainly limited to single robot, and rapid reconstruction of large-scale scenes remains challenging. Additionally, task-driven planning based on surface uncertainty is prone to being trapped in local optima. To this end, we propose the first 3DGS-based centralized multi-robot autonomous 3D reconstruction framework. To further reduce time cost of task generation and improve reconstruction quality, we integrate online open-vocabulary semantic segmentation with surface uncertainty of 3DGS, focusing view sampling on regions with high instance uncertainty. Finally, we develop a multi-robot collaboration strategy with mode and task assignments improving reconstruction quality while ensuring planning efficiency. Our method demonstrates the highest reconstruction quality among all planning methods and superior planning efficiency compared to existing multi-robot methods. We deploy our method on multiple robots, and results show that it can effectively plan view paths and reconstruct scenes with high quality.</p>
    </span>
    
  </div>
</div>
</li>
<li>
<!-- Refer to https://github.com/alshedivat/al-folio/blob/master/_layouts/bib.html
and 
https://github.com/Mayankm96/Mayankm96.github.io/blob/source/_layouts/bib.html -->
<div id="zeng2025diffusion" class="col three">
  <div style="clear: both;">
    <div style="">
        <img class="col bibone first" src="https://shepherd-gregory.github.io/assets/img/teaser/iotj_diffusion.png">
    </div>
  </div>
  <div class="col bibtwo last">
    
      <span class="title">Diffusion-based completion for multi-robot active scene reconstruction towards IoT applications</span>
      <span class="author">
        
          
          
          
          
          
          
            
              
                
                  Jing Zeng*,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  <em><b>Yang</b></em> <em><b>Xu<sup>*</sup></b></em>,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Tianle Liu,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Qi Ye,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Jiming Chen<sup>#</sup>
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em>IEEE Internet of Things Journal</em>
      
      
        
          2025
        
      
      </span>
    

    <span class="links">
    
      [<a class="abstract" style="color: $pub-theme-color">Abs</a>]
    
    
    
    
    
      [<a href="https://ieeexplore.ieee.org/document/11165337" target="_blank" rel="noopener noreferrer">Webpage</a>]
    
    
    
    
    
    
    
    
    </span>

    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p>Autonomous reconstruction of unknown scenes using multiple robots acting as mobile Internet of Things (IoT) nodes becomes a fundamental capability for extensive IoT applications, such as environmental monitoring, and search and rescue. However, existing multi-robot autonomous reconstruction approaches still suffer from incomplete observations, redundant generated coverage tasks, and overly distant assigned tasks. To this end, we first utilize a diffusion-based model for object completion in autonomously reconstructed scenes using 3D Gaussian Splatting, and obtain Gaussian mixture model-based object uncertainties to guide the robots in generating more accurate scanning tasks that fill holes and enhance reconstruction quality. We then design an efficient task filtering mechanism that utilizes clustering frontiers and exploration tasks, as well as instances and reconstruction tasks, enabling the elimination of redundant coverage tasks. We also devise a task reassignment mechanism for robots based on the required travel costs to avoid unnecessary detours, which further improves scanning efficiency. Extensive experimental results show that our method exhibits higher reconstruction quality and superior planning efficiency compared to existing multi-robot autonomous reconstruction methods.</p>
    </span>
    
  </div>
</div>
</li>
<li>
<!-- Refer to https://github.com/alshedivat/al-folio/blob/master/_layouts/bib.html
and 
https://github.com/Mayankm96/Mayankm96.github.io/blob/source/_layouts/bib.html -->
<div id="jia2025dhcme" class="col three">
  <div style="clear: both;">
    <div style="">
        <img class="col bibone first" src="https://shepherd-gregory.github.io/assets/img/teaser/iros_dhcme.png">
    </div>
  </div>
  <div class="col bibtwo last">
    
      <span class="title">DHC-ME: A Decentralized Hybrid Cooperative Approach for Multi-Robot Autonomous Exploration</span>
      <span class="author">
        
          
          
          
          
          
          
            
              
                
                  Wenhao Jia*,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  <em><b>Yang</b></em> <em><b>Xu<sup>*</sup></b></em>,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Chenglong Qian,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Xiufang Shi,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://scholar.google.com/citations?user=zK9tvo8AAAAJ&amp;hl=en" target="_blank" rel="noopener noreferrer">Jiming Chen</a>,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Liang Li<sup>#</sup>
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em></em>
        <br>
        <em>2025 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em>
      
      
        
          2025
        
      
      </span>
    

    <span class="links">
    
      [<a class="abstract" style="color: $pub-theme-color">Abs</a>]
    
    
    
    
    
    
    
    
    
    
    
    
      [<a href="https://github.com/NeSC-IV/DHC_ME" target="_blank" rel="noopener noreferrer">Code</a>]
    
    </span>

    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p>Multi-robot exploration in unknown environments is a fundamental task for multi-robot systems, which requires the coordination of the robots to avoid collisions and con- flicts while performing task allocation. Existing exploration strategies improve the efficiency of multi-robot exploration by modeling the multi-robot task allocation problem as a variant of the multiple traveling salesman problem. However, this is computationally intensive and difficult to deploy on physical platforms. Hence, this paper develops a hybrid strategy for range-sensing multi-robot exploration with effective team coordination, enabling a larger team dispersion degree and higher exploration efficiency. In addition, we present a novel multi-robot exploration point detection method suitable for narrow and dynamic environments, effectively reducing exploration failure and incompleteness. The Gazebo simulations demonstrate better exploration efficiency and the least time cost of our exploration framework compared with state-of-the-art methods, and real-world experiments also validate the effectiveness.</p>
    </span>
    
  </div>
</div>
</li>
<li>
<!-- Refer to https://github.com/alshedivat/al-folio/blob/master/_layouts/bib.html
and 
https://github.com/Mayankm96/Mayankm96.github.io/blob/source/_layouts/bib.html -->
<div id="pang2025pbmot" class="col three">
  <div style="clear: both;">
    <div style="">
        <img class="col bibone first" src="https://shepherd-gregory.github.io/assets/img/teaser/iros_pbmot.png">
    </div>
  </div>
  <div class="col bibtwo last">
    
      <span class="title">PB-MOT: Pose-aware Association Boosted Online 3D Multi-Object Tracking</span>
      <span class="author">
        
          
          
          
          
          
          
            
              
                
                  Bo Pang,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em><b>Yang Xu</b></em>,
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://scholar.google.com/citations?user=zK9tvo8AAAAJ&amp;hl=en" target="_blank" rel="noopener noreferrer">Jiming Chen</a>,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Liang Li<sup>#</sup>
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em></em>
        <br>
        <em>2025 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em>
      
      
        
          2025
        
      
      </span>
    

    <span class="links">
    
      [<a class="abstract" style="color: $pub-theme-color">Abs</a>]
    
    
    
    
    
    
    
    
    
    
    
    
    </span>

    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p>Robotic and autonomous driving platforms neces sitate efficient 3D multi-object tracking (MOT) that harmonizes geometric precision, motion robustness, and computational effi ciency. Traditional 3D MOT approaches face critical challenges: geometric similarity metrics (e.g., IoU-based) degrade at long ranges with high computational costs, while distance-based methods fail to capture object orientation and shape; the effects of occlusion and the intricate relative ego-object motion degrade tracking performance in dynamic scenes. To this end, we propose PB-MOT, an online framework integrating two key innovations: ego-motion-compensated state estimation that decouples dynamic interactions; and a rotated ellipse asso ciation mechanism unifying pose and shape-aware matching with adaptive distance constraints. Evaluations on the KITTI benchmark show our PB-MOT achieves a HOTA score of 81.94%, surpassing all published methods, at blazing 2,402.76 FPS on CPU, enabling real-time and high-fidelity perception and tracking for resource-constrained robotic systems.</p>
    </span>
    
  </div>
</div>
</li>
<li>
<!-- Refer to https://github.com/alshedivat/al-folio/blob/master/_layouts/bib.html
and 
https://github.com/Mayankm96/Mayankm96.github.io/blob/source/_layouts/bib.html -->
<div id="xu2025bato" class="col three">
  <div style="clear: both;">
    <div style="">
        <img class="col bibone first" src="https://shepherd-gregory.github.io/assets/img/teaser/tmech_bato.jpg">
    </div>
  </div>
  <div class="col bibtwo last">
    
      <span class="title">BATO: Bayesian Trajectory Optimization for Active Environmental Mapping using Autonomous Robots</span>
      <span class="author">
        
          
          
          
          
          
          
            
              
                <em><b>Yang Xu</b></em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Linlin Shi,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Liang Li,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Jiming Chen<sup>#</sup>
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em>IEEE/ASME Transactions on Mechatronics</em>
      
      
        
          2025
        
      
      </span>
    

    <span class="links">
    
      [<a class="abstract" style="color: $pub-theme-color">Abs</a>]
    
    
    
    
    
      [<a href="" target="_blank">Webpage</a>]
    
    
    
    
    
    
    
    
    </span>

    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p>Active mapping is a critical capability for robotic exploration tasks such as field rescue and environmental monitoring, where the objective is to plan informative trajectories that maximize environmental information acquisition under resource constraints in unknown environments. However, existing approaches often suffer from myopic planning and inefficient evaluation of informative trajectories. To address these challenges, we propose a Bayesian Trajectory Optimization (BATO) framework that integrates global trajectory optimization with local path smoothing for online active mapping. Specifically, we formulate the informative trajectory optimization problem as a heuristic search for target poses and leverage an efficient kernel-based Bayesian optimization approach to generate optimal pose suggestions over multiple epochs. Our Bayesian optimization method incorporates previously unexplored informative poses to improve solution optimality and introduces a novel information-theoretic objective function that effectively balances exploration and exploitation. Comprehensive evaluations in Gazebo simulations and real-world experiments demonstrate that BATO outperforms state-of-the-art methods in unstructured and cluttered environments, achieving superior active mapping performance.</p>
    </span>
    
  </div>
</div>
</li>
</ol>
    
      <ol class="bibliography">
<li>
<!-- Refer to https://github.com/alshedivat/al-folio/blob/master/_layouts/bib.html
and 
https://github.com/Mayankm96/Mayankm96.github.io/blob/source/_layouts/bib.html -->
<div id="xu2024uncertain" class="col three">
  <div style="clear: both;">
    <div style="">
        <img class="col bibone first" src="https://shepherd-gregory.github.io/assets/img/teaser/tase-ucrmi.png">
    </div>
  </div>
  <div class="col bibtwo last">
    
      <span class="title">Uncertainty-Aware Autonomous Robot Exploration Using Confidence-Rich Localization and Mapping</span>
      <span class="author">
        
          
          
          
          
          
          
            
              
                <em><b>Yang Xu</b></em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Ronghao Zheng<sup>#</sup>,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Senlin Zhang,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Meiqin Liu,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  and <a href="https://scholar.google.com/citations?user=Gudfky4AAAAJ" target="_blank" rel="noopener noreferrer">Junzhi Yu</a>
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em>IEEE Transactions on Automation Science and Engineering</em>
      
      
        
          2024
        
      
      </span>
    

    <span class="links">
    
      [<a class="abstract" style="color: $pub-theme-color">Abs</a>]
    
    
    
    
    
      [<a href="https://ieeexplore.ieee.org/abstract/document/10422987/" target="_blank" rel="noopener noreferrer">Webpage</a>]
    
    
    
    
    
    
    
    
    </span>

    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p>Information-based autonomous robot exploration methods, aiming to maximize the exploration rewards, e.g., mutual information (MI), get more prevalent in field robotics applications. However, most MI-based exploration methods assume known poses or use inaccurate pose uncertainty approximation, which may lead to deviation or even failure when exploring prior unknown environments. In this paper, we explicitly consider full-state (pose &amp; map) uncertainty for balancing exploration and localizability, i.e., avoiding the robot guiding itself to complex scenes with high exploration rewards but hard to localize. We first propose a Rao-Blackwellized particle filter-based localization and mapping framework (RBPF-CLAM) for a dense environmental map with continuous occupancy distribution. Then we develop a new closed-form particle weighting method to improve the localization accuracy and robustness. We further use these weighted particles to approximate the unknown pose uncertainty and combine it with our previous confidence-rich mutual information (CRMI) metric to evaluate the expected information utility of the robotâ€™s new control actions. This new information metric is called uncertain CRMI (UCRMI). Dataset experiments show our RBPF-CLAM improves about 44.7% average root mean square error than the state-of-the-art RBPF localization method, and real-world experimental results show that our UCRMI reduces the pose uncertainty about 32.85% more than CRMI and 25.36% time cost than UGPVR in the exploration of unknown and unstructured scenes given sparse measurements, which shows better performance than other state-of-the-art information metrics.</p>
    </span>
    
  </div>
</div>
</li>
<li>
<!-- Refer to https://github.com/alshedivat/al-folio/blob/master/_layouts/bib.html
and 
https://github.com/Mayankm96/Mayankm96.github.io/blob/source/_layouts/bib.html -->
<div id="xu2024online" class="col three">
  <div style="clear: both;">
    <div style="">
        <img class="col bibone first" src="https://shepherd-gregory.github.io/assets/img/teaser/tcasii-2024.png">
    </div>
  </div>
  <div class="col bibtwo last">
    
      <span class="title">Online Informative Path Planning of Autonomous Vehicles Using Kernel-Based Bayesian Optimization</span>
      <span class="author">
        
          
          
          
          
          
          
            
              
                <em><b>Yang Xu</b></em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Ronghao Zheng<sup>#</sup>,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Senlin Zhang,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Meiqin Liu,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  and <a href="https://scholar.google.com/citations?user=Gudfky4AAAAJ" target="_blank" rel="noopener noreferrer">Junzhi Yu</a>
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em>IEEE Transactions on Circuits and Systems II: Express Briefs</em>
      
      
        
          2024
        
      
      </span>
    

    <span class="links">
    
      [<a class="abstract" style="color: $pub-theme-color">Abs</a>]
    
    
    
    
    
      [<a href="https://ieeexplore.ieee.org/abstract/document/10443243/" target="_blank" rel="noopener noreferrer">Webpage</a>]
    
    
    
    
    
    
    
    
    </span>

    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p>To improve environmental information gathering of intelligent vehicles in unknown scenes, this brief presents a hierarchical online informative path planning (IPP) framework containing global action optimization and local path planning. Particularly, we propose a lightweight kernel-based Bayesian optimization for IPP (KBO-IPP) to facilitate highly efficient information utility evaluation and decision-making of control actions. Specifically, KBO-IPP can infer the exact environmental mutual information (MI) and associated uncertainties with an approximate logarithmic complexity, eliminating the need for explicit model training. We develop a new information-theoretic objective function consisting of travel cost and predicted MI values with uncertainties to achieve the balance between high MI values (exploitation) and high prediction variances (exploration). To enhance the optimality of IPP, the past unselected informative actions are also incorporated into the global Bayesian optimization. Online real-world experiments validate that our proposed method shows higher efficiency with comparable performance to modern methods in unknown, complex environments.</p>
    </span>
    
  </div>
</div>
</li>
</ol>
    
      <ol class="bibliography"><li>
<!-- Refer to https://github.com/alshedivat/al-folio/blob/master/_layouts/bib.html
and 
https://github.com/Mayankm96/Mayankm96.github.io/blob/source/_layouts/bib.html -->
<div id="xu2023care" class="col three">
  <div style="clear: both;">
    <div style="">
        <img class="col bibone first" src="https://shepherd-gregory.github.io/assets/img/teaser/care_2023.png">
    </div>
  </div>
  <div class="col bibtwo last">
    
      <span class="title">CARE: Confidence-rich Autonomous Robot Exploration using Bayesian Kernel Inference and Optimization</span>
      <span class="author">
        
          
          
          
          
          
          
            
              
                <em><b>Yang Xu</b></em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Ronghao Zheng<sup>#</sup>,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Senlin Zhang,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Meiqin Liu,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  and <a href="https://www.uts.edu.au/staff/shoudong.huang" target="_blank" rel="noopener noreferrer">Shoudong Huang</a>
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em>IEEE Robotics and Automation Letters (presented at ICRA 2024)</em>
      
      
        
          2023
        
      
      </span>
    

    <span class="links">
    
      [<a class="abstract" style="color: $pub-theme-color">Abs</a>]
    
    
      [<a href="http://arxiv.org/abs/2309.05200" target="_blank" rel="noopener noreferrer">arXiv</a>]
    
    
    
    
      [<a href="https://ieeexplore.ieee.org/abstract/document/10243037/" target="_blank" rel="noopener noreferrer">Webpage</a>]
    
    
    
    
      [<a href="https://shepherd-gregory.github.io/assets/documents/RAL23_arxiv_full.pdf" target="_blank">Supp</a>]
    
    
    
    
    
      [<a href="https://github.com/Shepherd-Gregory/BKIO-Exploration" target="_blank" rel="noopener noreferrer">Code</a>]
    
    </span>

    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p>In this letter, we consider improving the efficiency of information-based autonomous robot exploration in unknown and complex environments. We first utilize Gaussian process (GP) regression to learn a surrogate model to infer the confidence-rich mutual information (CRMI) of querying control actions, then adopt an objective function consisting of predicted CRMI values and prediction uncertainties to conduct Bayesian optimization (BO), i.e., GP-based BO (GPBO). The trade-off between the best action with the highest CRMI value (exploitation) and the action with high prediction variance (exploration) can be realized. To further improve the efficiency of GPBO, we propose a novel lightweight information gain inference method based on Bayesian kernel inference and optimization (BKIO), achieving an approximate logarithmic complexity without the need for training. BKIO can also infer the CRMI and generate the best action using BO with bounded cumulative regret, which ensures its comparable accuracy to GPBO with much higher efficiency. Extensive numerical and real-world experiments show the desired efficiency of our proposed methods without losing exploration performance in different unstructured, cluttered environments.</p>
    </span>
    
  </div>
</div>
</li></ol>
    
      <ol class="bibliography">
<li>
<!-- Refer to https://github.com/alshedivat/al-folio/blob/master/_layouts/bib.html
and 
https://github.com/Mayankm96/Mayankm96.github.io/blob/source/_layouts/bib.html -->
<div id="xu2022confidence" class="col three">
  <div style="clear: both;">
    <div style="">
        <img class="col bibone first" src="https://shepherd-gregory.github.io/assets/img/teaser/iros_clam.png">
    </div>
  </div>
  <div class="col bibtwo last">
    
      <span class="title">Confidence-rich Localization and Mapping based on Particle Filter for Robotic Exploration</span>
      <span class="author">
        
          
          
          
          
          
          
            
              
                <em><b>Yang Xu</b></em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Ronghao Zheng<sup>#</sup>,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Senlin Zhang,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Meiqin Liu
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em></em>
        <br>
        <em>2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em>
      
      
        
          2022
        
      
      </span>
    

    <span class="links">
    
      [<a class="abstract" style="color: $pub-theme-color">Abs</a>]
    
    
      [<a href="http://arxiv.org/abs/2309.05200" target="_blank" rel="noopener noreferrer">arXiv</a>]
    
    
      [<a href="https://youtu.be/t7awYSnC2dw" target="_blank" rel="noopener noreferrer">Video</a>]
    
    
    
      [<a href="https://ieeexplore.ieee.org/abstract/document/9981251/" target="_blank" rel="noopener noreferrer">Webpage</a>]
    
    
    
    
    
    
    
    
    </span>

    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p>This paper mainly studies the localization and mapping of range sensing robots in the confidence-rich map (CRM) and then extends it to provide a full state estimate for information-theoretic exploration. Most previous works about active simultaneous localization and mapping and exploration always assumed the known robot poses or utilized inaccurate information metrics to approximate pose uncertainty, resulting in imbalanced exploration performance and efficiency in the unknown environment. This inspires us to extend the confidence-rich mutual information (CRMI) with measurable pose uncertainty. Specifically, we propose a Rao- Blackwellized particle filter-based localization and mapping scheme (RBPF -CLAM) for CRM, then we develop a new closed-form weighting method to improve the localization accuracy without scan matching. We further derive the uncertain CRMI (UCRMI) with the weighted particles by a more accurate approximation. Simulations and experimental evaluations show the localization accuracy and exploration performance of the proposed methods.</p>
    </span>
    
  </div>
</div>
</li>
<li>
<!-- Refer to https://github.com/alshedivat/al-folio/blob/master/_layouts/bib.html
and 
https://github.com/Mayankm96/Mayankm96.github.io/blob/source/_layouts/bib.html -->
<div id="bai2022hierarchical" class="col three">
  <div style="clear: both;">
    <div style="">
        <img class="col bibone first" src="https://shepherd-gregory.github.io/assets/img/teaser/ras_bai.png">
    </div>
  </div>
  <div class="col bibtwo last">
    
      <span class="title">Hierarchical Multi-robot Strategies Synthesis and Optimization under Individual and Collaborative Temporal Logic Specifications</span>
      <span class="author">
        
          
          
          
          
          
          
            
              
                
                  Ruofei Bai,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Ronghao Zheng<sup>#</sup>,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em><b>Yang Xu</b></em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Meiqin Liu,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Senlin Zhang
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em>Robotics and Autonomous Systems</em>
      
      
        
          2022
        
      
      </span>
    

    <span class="links">
    
      [<a class="abstract" style="color: $pub-theme-color">Abs</a>]
    
    
      [<a href="http://arxiv.org/abs/2110.11162" target="_blank" rel="noopener noreferrer">arXiv</a>]
    
    
    
    
      [<a href="https://www.sciencedirect.com/science/article/pii/S0921889022000422" target="_blank" rel="noopener noreferrer">Webpage</a>]
    
    
    
    
    
    
    
    
    </span>

    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p>This paper presents a hierarchical framework for multi-robot temporal logic task planning. We assume that each robot has its individual task specification and the robots have to jointly satisfy a global collaborative task specification, both described in finite linear temporal logic. To reduce the overall computational complexity, a central server firstly extracts and decomposes a collaborative task sequence from the automaton corresponding to the collaborative task specification, and allocates the subtasks in the sequence to robots. The robots then synthesize their initial execution strategies based on locally constructed product automatons, which integrate task requirements of the assigned collaborative tasks and their individual task specifications. Further, to reduce robotsâ€™ wait time in collaborations, we propose a distributed execution strategy adjusting mechanism to iteratively improve the time efficiency of robots. Finally, we prove the completeness of the proposed framework under assumptions, and analyze its time complexity and optimality. Extensive simulation results verify the scalability and optimization efficiency of the proposed method.</p>
    </span>
    
  </div>
</div>
</li>
<li>
<!-- Refer to https://github.com/alshedivat/al-folio/blob/master/_layouts/bib.html
and 
https://github.com/Mayankm96/Mayankm96.github.io/blob/source/_layouts/bib.html -->
<div id="yang2022robust" class="col three">
  <div style="clear: both;">
    <div style="">
        <img class="col bibone first" src="https://shepherd-gregory.github.io/assets/img/teaser/tim-2022.png">
    </div>
  </div>
  <div class="col bibtwo last">
    
      <span class="title">Robust Inertial-aided Underwater Localization based on Imaging Sonar Keyframes</span>
      <span class="author">
        
          
          
          
          
          
          
            
              
                <em><b>Yang Xu</b></em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Ronghao Zheng<sup>#</sup>,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Senlin Zhang,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Meiqin Liu
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em>IEEE Transactions on Instrumentation and Measurement</em>
      
      
        
          2022
        
      
      </span>
    

    <span class="links">
    
      [<a class="abstract" style="color: $pub-theme-color">Abs</a>]
    
    
      [<a href="http://arxiv.org/abs/2106.16032" target="_blank" rel="noopener noreferrer">arXiv</a>]
    
    
    
    
      [<a href="https://ieeexplore.ieee.org/abstract/document/9729232/" target="_blank" rel="noopener noreferrer">Webpage</a>]
    
    
    
    
    
    
    
    
    </span>

    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p>This article focuses on feature-based underwater localization and navigation for autonomous underwater vehicles (AUVs) using 2-D imaging sonar measurements. The sparsity of underwater acoustic features and the loss of elevation angle in sonar images may introduce wrong feature matches or insufficient features for optimization-based underwater localization (i.e., underconstrained/degeneracy cases). This motivates us to propose a novel inertial-aided sliding window optimization framework to improve the estimation accuracy and the robustness to front-end outliers. Concretely, we first discriminate underconstrained/well-constrained sonar frames and define sonar keyframes (SKFs) based on the Jacobian matrix derived from odometry and sonar measurements. To utilize the past well-constrained SKFs mostly, we design a size-adjustable windowed back-end optimization scheme based on singular values. We also prove that the landmark triangulation failure (navigation problem) caused by sonar motion can be solved in 2-D scenes. Comparative simulation and evaluation on a public dataset show that the proposed method outperforms the existing ones in pose estimation and robustness even without loop closure and also ensures the real-time performance for online applications.</p>
    </span>
    
  </div>
</div>
</li>
</ol>
    
      <ol class="bibliography"><li>
<!-- Refer to https://github.com/alshedivat/al-folio/blob/master/_layouts/bib.html
and 
https://github.com/Mayankm96/Mayankm96.github.io/blob/source/_layouts/bib.html -->
<div id="yang2021crmi" class="col three">
  <div style="clear: both;">
    <div style="">
        <img class="col bibone first" src="https://shepherd-gregory.github.io/assets/img/teaser/ral_2021.png">
    </div>
  </div>
  <div class="col bibtwo last">
    
      <span class="title">CRMI: Confidence-rich Mutual Information for Information-theoretic Mapping</span>
      <span class="author">
        
          
          
          
          
          
          
            
              
                <em><b>Yang Xu</b></em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Ronghao Zheng<sup>#</sup>,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Meiqin Liu,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Senlin Zhang
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em>IEEE Robotics and Automation Letters (presented at IROS 2021)</em>
      
      
        
          2021
        
      
      </span>
    

    <span class="links">
    
      [<a class="abstract" style="color: $pub-theme-color">Abs</a>]
    
    
    
      [<a href="https://youtu.be/pUcGST2W_m8" target="_blank" rel="noopener noreferrer">Video</a>]
    
    
    
      [<a href="https://ieeexplore.ieee.org/abstract/document/9466474/" target="_blank" rel="noopener noreferrer">Webpage</a>]
    
    
    
    
    
    
    
    
      [<a href="https://github.com/Shepherd-Gregory/CRMI" target="_blank" rel="noopener noreferrer">Code</a>]
    
    </span>

    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p>This letter focuses on information-theoretic active mapping and exploration with beam-based range sensing robots. Traditional works based on hand-engineered inverse sensor model (ISM) mapping or kernel inference methods lead to imbalanced accuracy and efficiency. This motivates us to propose a new approach to compute mutual information more accurately, based on the continuous belief distribution over the occupancy map and called confidence-rich mutual information (CRMI). Specifically, we explicitly model the measurement dependencies between grid cells within the same measurement cone at each time step and derive the CRMI for each cell on all beams by introducing a more general beam-based sensor cause model (SCM), rather than the customized ISM. The time efficiency for CRMI mapping allows for online implementation as well. Extensive simulations and experiments show the desired exploratory behavior to unexplored and obscured regions for CRMI-based robot controllers in the unstructured and cluttered scene, even in large scale environment.</p>
    </span>
    
  </div>
</div>
</li></ol>
    
      <ol class="bibliography"><li>
<!-- Refer to https://github.com/alshedivat/al-folio/blob/master/_layouts/bib.html
and 
https://github.com/Mayankm96/Mayankm96.github.io/blob/source/_layouts/bib.html -->
<div id="xu2020keyframe" class="col three">
  <div style="clear: both;">
    <div style="">
        <img class="col bibone first" src="https://shepherd-gregory.github.io/assets/img/teaser/oceans20.png">
    </div>
  </div>
  <div class="col bibtwo last">
    
      <span class="title">Keyframe-Based Imaging Sonar Localization and Navigation using Elastic Windowed Optimization</span>
      <span class="author">
        
          
          
          
          
          
          
            
              
                <em><b>Yang Xu</b></em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Ronghao Zheng<sup>#</sup>,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Meiqin Liu,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Senlin Zhang
                
              
            
          
        
      </span>

      <span class="periodical">
      
        <em></em>
        <br>
        <em>Global Oceans 2020: Singapore â€“ U.S. Gulf Coast</em>
      
      
        
          2020
        
      
      </span>
    

    <span class="links">
    
      [<a class="abstract" style="color: $pub-theme-color">Abs</a>]
    
    
    
    
    
      [<a href="https://ieeexplore.ieee.org/abstract/document/9389045/" target="_blank" rel="noopener noreferrer">Webpage</a>]
    
    
    
    
    
    
    
    
    </span>

    <!-- Hidden abstract block -->
    
    <span class="abstract hidden">
      <p>This paper reports a sonar keyframe-based elastic windowed optimization scheme for underwater localization and navigation using a 2D forward-looking imaging sonar. Due to the sparse acoustic features and the missing elevation angle in sonar images, degeneracy cases (namely under-constrained), such as relative pose ambiguity, exist in underwater sonar simultaneous localization and mapping (SLAM). To extract and fully utilize informative constraints from past sonar frames, we first identify the degeneracy case and choose sonar keyframes (KFs) using the effective information volume criteria. Secondly, we present an elastic windowed optimization framework in which the window size is adjusted according to certain rules. This scheme is also more robust to outliers from the frontend. Finally, the feasibility and effectiveness of the proposed method are verified through the comparative simulation.</p>
    </span>
    
  </div>
</div>
</li></ol>
    
    </div>
  </article>

  <br>
  <br>
  <br>  
  <object>
	<script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&amp;w=300&amp;t=tt&amp;d=yxQ3Tb8hEv1Fhfl33BizwQwjKmY5JV97uM85OVIrSTc"></script>
  </object>
  <br>

</div>

    </div>

    <!-- Footer -->

    
<footer class="sticky-bottom mt-5">
  <div class="container">
    Â© Copyright 2025 Yang  Xu.
    Powered by <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme.

    
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
