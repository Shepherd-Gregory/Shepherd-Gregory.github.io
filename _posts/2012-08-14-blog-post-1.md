---
title: 'Brief review - CRMI: Confidence-rich Mutual Information for Information-theoretic Mapping'
collections: posts
date: 2012-08-14
permalink: /posts/2012/08/blog-post-1/
tags:
  - information-theoretic
---

我们近期的工作《CRMI: Confidence-rich Mutual Information for Information-theoretic Mapping》已经被IEEE Robotics and Automation Letters (RA-L) 和 IROS 2021 同时接收，并于 IROS 2021 会议上进行了口头汇报。视频地址（Youtube & Bilibili）：

1. Youtube: https://youtu.be/pUcGST2W_m8

2. Bilibili: https://www.bilibili.com/video/BV1vQ4y1e77y/

**摘要**：本文主要研究基于波束的距离传感（LiDAR，RGB-D，sonar等）机器人的信息论主动建图和探测。传统基于手动调节的反演传感模型（ISM）或核推理的建图方法等会导致精度和效率的不平衡。这促使我们提出了一种新的方法来更准确地计算互信息，这种方法基于占据地图上的连续置信度分布，称为置信度丰富互信息（CRMI）。具体来说，我们通过引入更通用的基于波束的因果传感模型（SCM），而不是根据任务或环境定制参数的ISM，在每个时间步对同一测量锥内的网格单元之间的测量依赖性进行显式建模，并导出所有波束上每个单元的CRMI。CRMI建图的时间效率也允许在线实现。大量的仿真和实验表明，基于CRMI的机器人控制器/规划器在非结构化和杂乱的场景中，甚至在大尺度环境中，可以对未知和模糊区域表现出期望的探测行为。

<img src="https://pic3.zhimg.com/80/v2-8d1507faa0a5b49a2d7cb92872f2f93c_720w.png?source=d16d100b" alt="img" style="zoom:50%;" />

图1 基于波束的传感器反射模型（诱因变量由红色格子表示）

![img](https://pic1.zhimg.com/80/v2-e59bc142c7ecd9dd0bd30dad84be883f_720w.png?source=d16d100b)

图2 (a, b) CRMI/OGMI of INTEL Lab Dataset ; (c, d) CRMI/Aerial view of Freiburg Campus Dataset

<img src="https://pic1.zhimg.com/80/v2-258918509a2931f9c14886ae6d523269_720w.png?source=d16d100b" alt="img" style="zoom: 67%;" />

图3 (a, b) OGMI/CRMI-based IIG Graph (c, d) 信息增益对比/MI对比



**总结**：本文主要为距离传感机器人的信息建图和探测提供了一种新的解决方案，可以有效地计算出更精确的互信息量。值得注意的是，传感器传感锥内的测量相关性通过传感因果模型融合。更新每个被观测单元占据值的概率密度函数并将其用于定义CRMI。仿真结果表明，该方法具有与OGMI相似的探测性能，但在大的杂乱、非结构化环境中具有较高的精度和一致性。该方法还可以推广到三维场景。未来的工作包括加速CRMI计算的方法、更多的野外探测实验和基于连续占据地图（COM）的信息论探测。

【参考文献】

Y. Xu, R. Zheng, M. Liu and S. Zhang, "CRMI: Confidence-Rich Mutual Information for Information-Theoretic Mapping," *IEEE Robotics and Automation Letters*, vol. 6, no. 4, pp. 6434-6441, Oct. 2021, doi: [10.1109/LRA.2021.3093023](https://ieeexplore.ieee.org/document/9466474).


------